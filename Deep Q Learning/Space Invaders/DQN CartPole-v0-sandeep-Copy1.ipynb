{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q Learning with Atari¬© Space Invaders¬© üïπÔ∏èüëæ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version:  2.0.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import tensorflow as tf      # Deep Learning library\n",
    "import numpy as np           # Handle matrices\n",
    "#import retro                 # Retro Environment\n",
    "from PIL import Image\n",
    "import gym\n",
    "from datetime import datetime\n",
    "from packaging import version\n",
    "from skimage import transform # Help us to preprocess the frames\n",
    "from skimage.color import rgb2gray # Help us to gray our frames\n",
    "\n",
    "import matplotlib.pyplot as plt # Display graphs\n",
    "\n",
    "from collections import deque# Ordered collection with ends\n",
    "\n",
    "import random\n",
    "\n",
    "# Load the TensorBoard notebook extension.\n",
    "%load_ext tensorboard\n",
    "import warnings # This ignore all the warning messages that are normally printed during the training because of skiimage\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "print(\"TensorFlow version: \", tf.__version__)\n",
    "assert version.parse(tf.__version__).release[0] >= 2, \\\n",
    "    \"This notebook requires TensorFlow 2.0 or above.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make('CartPole-v1')  #CartPole-v0,MsPacman-v0,Hopper-v3,MountainCar-v0\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample()) # take a random action\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of our frame is:  Box(4,)\n",
      "The action size is :  2\n"
     ]
    }
   ],
   "source": [
    "# Create our environment\n",
    "#env = retro.make(game='SpaceInvaders-Atari2600')\n",
    "\n",
    "print(\"The size of our frame is: \", env.observation_space)\n",
    "print(\"The action size is : \", env.action_space.n)\n",
    "\n",
    "# Here we create an hot encoded version of our actions\n",
    "# possible_actions = [[1, 0, 0, 0, 0, 0, 0, 0], [0, 1, 0, 0, 0, 0, 0, 0, 0]...]\n",
    "#possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0, 1}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set([env.action_space.sample() for i in range(100)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-inf, inf)\n"
     ]
    }
   ],
   "source": [
    "print(env.reward_range)\n",
    "\n",
    "#print(env.observation_space.high)\n",
    "\n",
    "#print(env.observation_space.low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "state= env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02733327, -0.02475361,  0.01364489, -0.04023929])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Define the preprocessing functions ‚öôÔ∏è\n",
    "### preprocess_frame\n",
    "Preprocessing is an important step, <b>because we want to reduce the complexity of our states to reduce the computation time needed for training.</b>\n",
    "<br><br>\n",
    "Our steps:\n",
    "- Grayscale each of our frames (because <b> color does not add important information </b>).\n",
    "- Crop the screen (in our case we remove the part below the player because it does not add any useful information)\n",
    "- We normalize pixel values\n",
    "- Finally we resize the preprocessed frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "original = obs\n",
    "grayscale = rgb2gray(obs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(original)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(grayscale, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    preprocess_frame:\n",
    "    Take a frame.\n",
    "    Grayscale it\n",
    "    Resize it.\n",
    "        __________________\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |                 |\n",
    "        |_________________|\n",
    "        \n",
    "        to\n",
    "        _____________\n",
    "        |            |\n",
    "        |            |\n",
    "        |            |\n",
    "        |____________|\n",
    "    Normalize it.\n",
    "    \n",
    "    return preprocessed_frame\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "def preprocess_frame(frame,resize_shape):\n",
    "    frame = Image.fromarray(frame)\n",
    "    w,h= frame.size\n",
    "    upper_y,lower_y,left_x,right_x=.1*h,.88*h,.05*w,.8*w\n",
    "    left=left_x; upper = upper_y; right = right_x; lower= lower_y\n",
    "    frame_cropped=frame.crop(box=(left,upper,right,lower))\n",
    "    frame_cropped = frame_cropped.resize(resize_shape)\n",
    "    frame_cropped=np.array(frame_cropped)\n",
    "    frame_cropped=frame_cropped/255.\n",
    "    grey = rgb2gray(frame_cropped)\n",
    "    return(grey)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'obs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-ba10f27fe6a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprocessed_obs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocess_frame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'obs' is not defined"
     ]
    }
   ],
   "source": [
    "processed_obs = preprocess_frame(obs,((state_size[1],state_size[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 84)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "original = obs\n",
    "grayscale = rgb2gray(obs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(original)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(processed_obs, cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### stack_frames\n",
    "As explained in this really <a href=\"https://danieltakeshi.github.io/2016/11/25/frame-skipping-and-preprocessing-for-deep-q-networks-on-atari-2600-games/\">  good article </a> we stack frames.\n",
    "\n",
    "Stacking frames is really important because it helps us to **give have a sense of motion to our Neural Network.**\n",
    "\n",
    "BUT, **we don't stack each frames, we skip 4 frames at each timestep**. This means that only every fourth frame is considered. And then, we use this frame to form the stack_frame.\n",
    "\n",
    "**The frame skipping method is already implemented in the library.**\n",
    "\n",
    "- First we preprocess frame\n",
    "- Then we append the frame to the deque that automatically **removes the oldest frame**\n",
    "- Finally we **build the stacked state**\n",
    "\n",
    "This is how work stack:\n",
    "- For the first frame, we feed 4 frames\n",
    "- At each timestep, **we add the new frame to deque and then we stack them to form a new stacked frame**\n",
    "- And so on\n",
    "<img src=\"https://github.com/simoninithomas/Deep_reinforcement_learning_Course/blob/master/Deep%20Q%20Learning/Space%20Invaders/assets/stack_frames.png\" />\n",
    "- If we're done, **we create a new stack with 4 new frames (because we are in a new episode)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "original = obs\n",
    "grayscale = rgb2gray(obs)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(8, 4))\n",
    "ax = axes.ravel()\n",
    "\n",
    "ax[0].imshow(obs1)\n",
    "ax[0].set_title(\"Original\")\n",
    "ax[1].imshow(xyz[-1], cmap=plt.cm.gray)\n",
    "ax[1].set_title(\"Grayscale\")\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 110)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xyz[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[110, 84, 4]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stack_frames(frame,stack_frame_deque,initial=False):\n",
    "    global state_size\n",
    "    resize_shape = (state_size[1],state_size[0])\n",
    "    frame = preprocess_frame(frame,resize_shape)\n",
    "    if initial:\n",
    "        [stack_frame_deque.append(frame) for i in range(state_size[2])]\n",
    "    else:\n",
    "        stack_frame_deque.append(frame)\n",
    "    stacked_frame = np.stack(stack_frame_deque,axis=2)\n",
    "    return(stacked_frame,stack_frame_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'state_size' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-8d3a96af2328>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mstack_frame_deque\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdeque\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstate_size\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'state_size' is not defined"
     ]
    }
   ],
   "source": [
    "stack_frame_deque = deque(maxlen=state_size[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_frame,stack_frame_deque = stack_frames(obs,stack_frame_deque,initial=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 84, 4)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 0.49580196078431377)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs.max(),stacked_frame.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs1 = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_frame,stack_frame_deque = stack_frames(obs1,stack_frame_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181, 0.49580196078431377)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs1.max(),stacked_frame.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xyz= list(stack_frame_deque)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(210, 160, 3)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Set up our hyperparameters ‚öóÔ∏è\n",
    "In this part we'll set up our different hyperparameters. But when you implement a Neural Network by yourself you will **not implement hyperparamaters at once but progressively**.\n",
    "\n",
    "- First, you begin by defining the neural networks hyperparameters when you implement the model.\n",
    "- Then, you'll add the training hyperparameters when you implement the training algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### MODEL HYPERPARAMETERS\n",
    "state_size = [110, 84, 4]      # Our input is a stack of 4 frames hence 110x84x4 (Width, height, channels) \n",
    "action_size = env.action_space.n # 8 possible actions\n",
    "learning_rate =  0.00025      # Alpha (aka learning rate)\n",
    "\n",
    "### TRAINING HYPERPARAMETERS\n",
    "total_episodes = 50            # Total episodes for training\n",
    "max_steps = 50000              # Max possible steps in an episode\n",
    "batch_size = 64                # Batch size\n",
    "\n",
    "# Exploration parameters for epsilon greedy strategy\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.00001           # exponential decay rate for exploration prob\n",
    "\n",
    "# Q learning hyperparameters\n",
    "gamma = 0.9                    # Discounting rate\n",
    "\n",
    "### MEMORY HYPERPARAMETERS\n",
    "pretrain_length = batch_size   # Number of experiences stored in the Memory when initialized for the first time\n",
    "memory_size = 1000000          # Number of experiences the Memory can keep\n",
    "\n",
    "### PREPROCESSING HYPERPARAMETERS\n",
    "stack_size = 4                 # Number of frames stacked\n",
    "\n",
    "### MODIFY THIS TO FALSE IF YOU JUST WANT TO SEE THE TRAINED AGENT\n",
    "training = False\n",
    "\n",
    "## TURN THIS TO TRUE IF YOU WANT TO RENDER THE ENVIRONMENT\n",
    "episode_render = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Create our Deep Q-learning Neural Network model üß†\n",
    "<img src=\"https://raw.githubusercontent.com/simoninithomas/Deep_reinforcement_learning_Course/master/DQN/Space%20Invaders/assets/DQN%20Illustrations.png\" alt=\"Model\" />\n",
    "This is our Deep Q-learning model:\n",
    "- We take a stack of 4 frames as input\n",
    "- It passes through 3 convnets\n",
    "- Then it is flatened\n",
    "- Finally it passes through 2 FC layers\n",
    "- It outputs a Q value for each actions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "inputs = keras.Input(shape=(state_size),name='maininput')\n",
    "x = layers.Conv2D(filters= 32, kernel_size = 8 , strides= 2, padding = 'valid', activation = 'elu',name='conv1_layer')(inputs)\n",
    "x = layers.Conv2D(filters= 64, kernel_size = 4 , strides= 2, padding = 'valid', activation = 'elu',name='conv2_layer')(x)\n",
    "x = layers.Conv2D(filters= 64, kernel_size = 3 , strides= 2, padding = 'valid', activation = 'elu',name='conv3_layer')(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(512, activation='sigmoid', name='fc1')(x)\n",
    "qvalues_actions = layers.Dense(8, activation='softmax', name='fc2')(x)\n",
    "# Instantiate an end-to-end model  \n",
    "model = keras.Model(inputs=[inputs],\n",
    "                    outputs=[qvalues_actions])\n",
    "\n",
    "model.compile(\n",
    "    loss='mse', # keras.losses.mean_squared_error\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=learning_rate\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "keras.utils.plot_model(model, 'multi_input_and_output_model.png', show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "maininput (InputLayer)       [(None, 110, 84, 4)]      0         \n",
      "_________________________________________________________________\n",
      "conv1_layer (Conv2D)         (None, 52, 39, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2_layer (Conv2D)         (None, 25, 18, 64)        32832     \n",
      "_________________________________________________________________\n",
      "conv3_layer (Conv2D)         (None, 12, 8, 64)         36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6144)              0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 512)               3146240   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 8)                 4104      \n",
      "=================================================================\n",
      "Total params: 3,228,328\n",
      "Trainable params: 3,228,328\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Experience Replay üîÅ\n",
    "Now that we create our Neural Network, **we need to implement the Experience Replay method.** <br><br>\n",
    "Here we'll create the Memory object that creates a deque.A deque (double ended queue) is a data type that **removes the oldest element each time that you add a new element.**\n",
    "\n",
    "This part was taken from Udacity : <a href=\"https://github.com/udacity/deep-learning/blob/master/reinforcement/Q-learning-cart.ipynb\" Cartpole DQN</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self,maxsize):\n",
    "        self.buffer=deque(maxlen=\n",
    "                          maxsize)\n",
    "    def add(self,single_memory):\n",
    "        self.buffer.append(single_memory)\n",
    "    def sample(self,batchsize):\n",
    "        return(random.sample(list(self.buffer), batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory(maxsize=memory_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we'll **deal with the empty memory problem**: we pre-populate our memory by taking random actions and storing the experience (state, action, reward, next_state)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_actions = np.array(np.identity(env.action_space.n,dtype=int).tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 0, 0, 1, 1, 0], dtype=int8)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.add(('3','3'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "deque([3, ('3', '3')])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.buffer"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "a=[list(env.action_space.sample()) for i in range(10000)]\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    # action_space will by MultiBinary(16) now instead of MultiBinary(8)\n",
    "    # the bottom half of the actions will be for player 1 and the top half for player 2\n",
    "    obs, rew, done, info = env.step(env.action_space.sample())\n",
    "    # rew will be a list of [player_1_rew, player_2_rew]\n",
    "    # done and info will remain the same\n",
    "    env.render()\n",
    "    if done:\n",
    "        obs = env.reset()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()\n",
    "initial = True\n",
    "stack_frame_deque = deque(maxlen=state_size[2])\n",
    "for i in range(batch_size):\n",
    "    #rand_action = env.action_space.sample()\n",
    "    rand_action = possible_actions[random.randint(0,env.action_space.n-1)]\n",
    "    #print(rand_action)\n",
    "    if initial:\n",
    "        stacked_frame,stack_frame_deque = stack_frames(state,stack_frame_deque,initial=True)\n",
    "    else:\n",
    "        stacked_frame,stack_frame_deque = stack_frames(state,stack_frame_deque,initial=False)\n",
    "    new_state,reward,done,info=env.step(rand_action)\n",
    "    #print(reward)\n",
    "    resize= (state_size[0],state_size[1])\n",
    "    new_stacked_frame,stack_frame_deque = stack_frames(new_state,stack_frame_deque,initial=False)\n",
    "    #print(new_stacked_frame.shape)\n",
    "    state= new_state\n",
    "    \n",
    "    initial = False\n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        new_stacked_frame = np.zeros(shape=new_stacked_frame.shape)\n",
    "    memory.add((stacked_frame,new_stacked_frame,reward,info,done))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.randint(0,env.action_space.n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(memory.buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(memory.buffer)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stacked_frame,new_stacked_frame,reward,info,done=list(memory.buffer)[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 84, 4)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 84, 4)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_stacked_frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'height': 82, 'lives': 3, 'scoreHi': 0, 'scoreLo': 0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observation (object): agent's observation of the current environment\n",
    "    reward (float) : amount of reward returned after previous action\n",
    "    done (bool): whether the episode has ended, in which case further step() calls will return undefined results\n",
    "    info (dict): contains auxiliary diagnostic information (helpful for debugging, and sometimes learning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(84, 110, 4)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[110, 84, 4] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 84, 110, 4)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.expand_dims(stacked_frame, axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04875204, 0.09034419, 0.11778502, 0.13086842, 0.20129293,\n",
       "        0.07460781, 0.21725003, 0.11909948]], dtype=float32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(stacked_frame, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 8)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(np.expand_dims(stacked_frame, axis=0)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6], dtype=int64)"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(model.predict(np.expand_dims(stacked_frame, axis=0)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Set up Tensorboard üìä\n",
    "For more information about tensorboard, please watch this <a href=\"https://www.youtube.com/embed/eBbEDRsCmv4\">excellent 30min tutorial</a> <br><br>\n",
    "To launch tensorboard : `tensorboard --logdir=/tensorboard/dqn/1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"logs/scalars/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "model.fit(\n",
    "    x_train, # input\n",
    "    y_train, # output\n",
    "    batch_size=train_size,\n",
    "    verbose=0, # Suppress chatty output; use Tensorboard instead\n",
    "    epochs=100,\n",
    "    callbacks=[tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sample_list = memory.sample(batchsize=batch_size)\n",
    "batch_states = batch_sample_list[0]\n",
    "batch_new_states = batch_sample_list[1]\n",
    "batch_rewards = batch_sample_list[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110, 84, 4)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_rewards[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "64"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(batch_sample_list).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(64, 3)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.stack(batch_sample_list,axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Losses\n",
    "tf.summary.scalar(\"Loss\", DQNetwork.loss)\n",
    "\n",
    "write_op = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Train our Agent üèÉ‚Äç‚ôÇÔ∏è\n",
    "\n",
    "Our algorithm:\n",
    "<br>\n",
    "* Initialize the weights\n",
    "* Init the environment\n",
    "* Initialize the decay rate (that will use to reduce epsilon) \n",
    "<br><br>\n",
    "* **For** episode to max_episode **do** \n",
    "    * Make new episode\n",
    "    * Set step to 0\n",
    "    * Observe the first state $s_0$\n",
    "    <br><br>\n",
    "    * **While** step < max_steps **do**:\n",
    "        * Increase decay_rate\n",
    "        * With $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s_t,a)$\n",
    "        * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "        * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "        * Sample random mini-batch from $D$: $<s, a, r, s'>$\n",
    "        * Set $\\hat{Q} = r$ if the episode ends at $+1$, otherwise set $\\hat{Q} = r + \\gamma \\max_{a'}{Q(s', a')}$\n",
    "        * Make a gradient descent step with loss $(\\hat{Q} - Q(s, a))^2$\n",
    "    * **endfor**\n",
    "    <br><br>\n",
    "* **endfor**\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This function will do the part\n",
    "With œµœµ select a random action atat, otherwise select at=argmaxaQ(st,a)\n",
    "\"\"\"\n",
    "def predict_action(batch,model,possible_actions):\n",
    "    return(possible_actions[np.argmax(model.predict(np.expand_dims(stacked_frame, axis=0)),axis=1)[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: 110.0 Explore P: 0.9812 Training Loss 0.3048\n",
      "Model Saved\n",
      "Episode: 1 Total reward: 25.0 Explore P: 0.9664 Training Loss 0.0086\n",
      "Episode: 2 Total reward: 60.0 Explore P: 0.9512 Training Loss 0.0056\n",
      "Episode: 3 Total reward: 195.0 Explore P: 0.9276 Training Loss 0.0204\n",
      "Episode: 4 Total reward: 210.0 Explore P: 0.9039 Training Loss 0.0002\n",
      "Episode: 5 Total reward: 210.0 Explore P: 0.8819 Training Loss 0.0003\n",
      "Model Saved\n",
      "Episode: 6 Total reward: 575.0 Explore P: 0.8397 Training Loss 0.0000\n",
      "Episode: 7 Total reward: 225.0 Explore P: 0.8170 Training Loss 0.0007\n",
      "Episode: 8 Total reward: 180.0 Explore P: 0.7971 Training Loss 0.0074\n",
      "Episode: 9 Total reward: 215.0 Explore P: 0.7811 Training Loss 0.0084\n",
      "Episode: 10 Total reward: 105.0 Explore P: 0.7654 Training Loss 0.0242\n",
      "Model Saved\n",
      "Episode: 11 Total reward: 210.0 Explore P: 0.7478 Training Loss 0.0460\n",
      "Episode: 12 Total reward: 175.0 Explore P: 0.7289 Training Loss 9.6785\n",
      "Episode: 13 Total reward: 210.0 Explore P: 0.7122 Training Loss 0.0167\n",
      "Episode: 14 Total reward: 180.0 Explore P: 0.6956 Training Loss 9.7288\n",
      "Episode: 15 Total reward: 140.0 Explore P: 0.6800 Training Loss 0.0024\n",
      "Model Saved\n",
      "Episode: 16 Total reward: 225.0 Explore P: 0.6636 Training Loss 0.0001\n",
      "Episode: 17 Total reward: 575.0 Explore P: 0.6394 Training Loss 0.0041\n",
      "Episode: 18 Total reward: 180.0 Explore P: 0.6242 Training Loss 0.0002\n",
      "Episode: 19 Total reward: 470.0 Explore P: 0.6068 Training Loss 0.0075\n",
      "Episode: 20 Total reward: 215.0 Explore P: 0.5910 Training Loss 0.0000\n",
      "Model Saved\n",
      "Episode: 21 Total reward: 335.0 Explore P: 0.5770 Training Loss 0.0170\n",
      "Episode: 22 Total reward: 120.0 Explore P: 0.5646 Training Loss 0.0196\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Test and Watch our Agent play üëÄ\n",
    "Now that we trained our agent, we can test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
